{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pytz\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'NUM_CLASS':34,\n",
    "    'IMG_SIZE':512,\n",
    "    'EPOCHS':1,\n",
    "    'LR':3e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, targets_boxes, targets_labels = tuple(zip(*batch))\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(targets_boxes)):\n",
    "        target = {\n",
    "            \"boxes\": targets_boxes[i],\n",
    "            \"labels\": targets_labels[i]\n",
    "        }\n",
    "        targets.append(target)\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transforms=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "        self.imgs = sorted(glob.glob(root+'/*.png'))\n",
    "        \n",
    "        if train:\n",
    "            self.boxes = sorted(glob.glob(root+'/*.txt'))\n",
    "\n",
    "    def parse_boxes(self, box_path):\n",
    "        with open(box_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for line in lines:\n",
    "            values = list(map(float, line.strip().split(' ')))\n",
    "            class_id = int(values[0])\n",
    "            x_min, y_min = int(round(values[1])), int(round(values[2]))\n",
    "            x_max, y_max = int(round(max(values[3], values[5], values[7]))), int(round(max(values[4], values[6], values[8])))\n",
    "\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            labels.append(class_id)\n",
    "\n",
    "        return torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "        img = cv2.imread(self.imgs[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img /= 255.0\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "\n",
    "        if self.train:\n",
    "            box_path = self.boxes[idx]\n",
    "            boxes, labels = self.parse_boxes(box_path)\n",
    "            labels += 1 # Background = 0\n",
    "\n",
    "            if self.transforms is not None:\n",
    "                transformed = self.transforms(image=img, bboxes=boxes, labels=labels)\n",
    "                img, boxes, labels = transformed[\"image\"], transformed[\"bboxes\"], transformed[\"labels\"]\n",
    "                \n",
    "            return img, torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        else:\n",
    "            if self.transforms is not None:\n",
    "                transformed = self.transforms(image=img)\n",
    "                img = transformed[\"image\"]\n",
    "            file_name = img_path.split('/')[-1]\n",
    "            return file_name, img, width, height\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "        ToTensorV2(),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
    "\n",
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../src/data/'\n",
    "\n",
    "train_dataset = CustomDataset(data_dir+'train', train=True, transforms=get_train_transforms())\n",
    "test_dataset = CustomDataset(data_dir+'test', train=False, transforms=get_test_transforms())\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes=CFG['NUM_CLASS']+1):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for images, targets in tqdm(iter(train_loader)):\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(losses.item())\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        tr_loss = np.mean(train_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch}] Train loss : [{tr_loss:.5f}]\\n')\n",
    "        \n",
    "        if best_loss > tr_loss:\n",
    "            best_loss = tr_loss\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "sub_dir = now.strftime('%m%d_%H%M%S')\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "infer_model = train(model, train_loader, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_denormalize(x1, y1, x2, y2, width, height):\n",
    "    x1 = (x1 / CFG['IMG_SIZE']) * width\n",
    "    y1 = (y1 / CFG['IMG_SIZE']) * height\n",
    "    x2 = (x2 / CFG['IMG_SIZE']) * width\n",
    "    y2 = (y2 / CFG['IMG_SIZE']) * height\n",
    "    return x1.item(), y1.item(), x2.item(), y2.item()\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    results = pd.read_csv(data_dir+'/sample_submission.csv')\n",
    "\n",
    "    for img_files, images, img_width, img_height in tqdm(iter(test_loader)):\n",
    "        images = [img.to(device) for img in images]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        for idx, output in enumerate(outputs):\n",
    "            boxes = output[\"boxes\"].cpu().numpy()\n",
    "            labels = output[\"labels\"].cpu().numpy()\n",
    "            scores = output[\"scores\"].cpu().numpy()\n",
    "\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                x1, y1, x2, y2 = box\n",
    "                x1, y1, x2, y2 = box_denormalize(x1, y1, x2, y2, img_width[idx], img_height[idx])\n",
    "                results = results.append({\n",
    "                    \"file_name\": img_files[idx],\n",
    "                    \"class_id\": label-1,\n",
    "                    \"confidence\": score,\n",
    "                    \"point1_x\": x1, \"point1_y\": y1,\n",
    "                    \"point2_x\": x2, \"point2_y\": y1,\n",
    "                    \"point3_x\": x2, \"point3_y\": y2,\n",
    "                    \"point4_x\": x1, \"point4_y\": y2\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    # 결과를 CSV 파일로 저장\n",
    "    results.to_csv(f'../submit/{sub_dir}_baseline_submit.csv', index=False)\n",
    "    print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defective_wallpaper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
